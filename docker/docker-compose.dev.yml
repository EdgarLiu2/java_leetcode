# Docker mirror:
#   https://r3cphckj.mirror.aliyuncs.com
#   https://hub-mirror.c.163.com
#   https://docker.mirrors.ustc.edu.cn

services:
###############################################################################
# Tools
  # ubuntu:
    # image: ubuntu:latest
    # hostname: ubuntu
    # domainname: internal
    # restart: always
    # tty: true
  # sonarqube:
    # image: sonarqube
    # hostname: sonarqube-1
    # domainname: internal
    # ports:
      # - 9000:9000
###############################################################################
# Configuration Center
  etcd-0:
      image: 'bitnami/etcd:latest'
      hostname: etcd-0
      domainname: internal
      environment:
        - TZ=CST-8
        - ALLOW_NONE_AUTHENTICATION=yes
        - ETCD_ADVERTISE_CLIENT_URLS=http://etcd-0:2379
      ports:
        - 2379:2379
        - 2380:2380
      restart: unless-stopped
      healthcheck:
        test: ["CMD", "curl", "-f", "http://localhost:2379"]
        interval: 30s
        timeout: 10s
        retries: 5
  # etcd-0:
  #     image: quay.io/coreos/etcd:latest
  #     hostname: etcd-0
  #     domainname: internal
  #     environment:
  #       - TZ=CST-8
  #     command: [
  #       "etcd",
  #       "--name=etcd-0",
  #       "--advertise-client-urls=http://etcd-0:2379,http://etcd-0:4001",
  #       "--listen-client-urls=http://0.0.0.0:2379,http://0.0.0.0:4001",
  #       "--initial-advertise-peer-urls=http://etcd-0:2380",
  #       "--listen-peer-urls=http://0.0.0.0:2380",
  #       "--initial-cluster-token=etcd-cluster-1",
  #       "--initial-cluster=etcd-0=http://etcd-0:2380",
  #       "--initial-cluster-state=new"
  #     ]
  #     ports:
  #       - 2379:2379
  #       - 2380:2380
  #       - 4001:4001
  #     restart: unless-stopped
  #     healthcheck:
  #       test: ["CMD", "curl", "-f", "http://localhost:2379"]
  #       interval: 30s
  #       timeout: 10s
  #       retries: 5
  # etcd-1:
  #   image: quay.io/coreos/etcd:latest
  #   hostname: etcd-1
  #   domainname: internal
  #   environment:
  #     - TZ=CST-8
  #   command: etcd -name etcd-1 -advertise-client-urls http://0.0.0.0:2379 -listen-client-urls http://0.0.0.0:2379 -listen-peer-urls http://0.0.0.0:2380 -initial-cluster-token etcd-cluster -initial-cluster "etcd-1=http://etcd-1:2380,etcd-2=http://etcd-2:2380,etcd-3=http://etcd-3:2380" -initial-cluster-state new
  #   ports:
  #     - 2379:2379
  #     - 2380:2380
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:2379"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  # etcd-2:
  #   image: quay.io/coreos/etcd:latest
  #   hostname: etcd-2
  #   domainname: internal
  #   environment:
  #     - TZ=CST-8
  #   command: etcd -name etcd-2 -advertise-client-urls http://0.0.0.0:2379 -listen-client-urls http://0.0.0.0:2379 -listen-peer-urls http://0.0.0.0:2380 -initial-cluster-token etcd-cluster -initial-cluster "etcd-1=http://etcd-1:2380,etcd-2=http://etcd-2:2380,etcd-3=http://etcd-3:2380" -initial-cluster-state new
  #   ports:
  #     - 2379
  #     - 2380
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:2379"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  # etcd-3:
  #   image: quay.io/coreos/etcd:latest
  #   hostname: etcd-3
  #   domainname: internal
  #   environment:
  #     - TZ=CST-8
  #   command: etcd -name etcd-3 -advertise-client-urls http://0.0.0.0:2379 -listen-client-urls http://0.0.0.0:2379 -listen-peer-urls http://0.0.0.0:2380 -initial-cluster-token etcd-cluster -initial-cluster "etcd-1=http://etcd-1:2380,etcd-2=http://etcd-2:2380,etcd-3=http://etcd-3:2380" -initial-cluster-state new
  #   ports:
  #     - 2379
  #     - 2380
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:2379"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  # zookeeper-1:
  #   image: wurstmeister/zookeeper:latest
  #   hostname: zookeeper-1
  #   domainname: internal
  #   ports:
  #     - 2181:2181
  #   restart: unless-stopped
###############################################################################
# Middleware
  # canal-server:
    # image: canal/canal-server:v1.1.4
    # hostname: canal-server
    # domainname: internal
    # depends_on:
      # - mysql-db
    # environment:
      # - ENV=DEV
      # - canal.instance.master.address=mysql-db:3306
      # - canal.instance.dbUsername=canal
      # - canal.instance.dbPassword=canal
      # - canal.instance.connectionCharset=UTF-8
      # - canal.instance.tsdb.enable=true
      # - canal.instance.gtidon=false
      # - canal.instance.filter.regex=.*\\..* 
    # ports:
      # - 11111:11111
    # restart: unless-stopped
  # zipkin-1: # https://github.com/openzipkin/zipkin#quick-start
  #   image: openzipkin/zipkin-slim
  #   hostname: zipkin-1
  #   domainname: internal
  #   ports:
  #     - 9411:9411
  #   restart: unless-stopped
  # consul-1:
  #   image: consul:latest
  #   hostname: consul-1
  #   domainname: internal
  #   ports:
  #     - 8500:8500
  #   command: "agent -server -bootstrap -ui -client 0.0.0.0"
  #   restart: unless-stopped
  # spring-boot-admin:
  #   image: slydeveloper/spring-boot-admin:latest
  #   hostname: spring-boot-admin
  #   domainname: internal
  #   ports:
  #     - 1111:1111
  #   restart: unless-stopped
  #   healthcheck:
  #     test: "curl -sS http://localhost:1111/health"
  #     interval: 30s
  #     timeout: 60s
  #     retries: 120
###############################################################################
# Prometheus & Grafana
  # prometheus:
  #   image: prom/prometheus:latest
  #   hostname: prometheus
  #   domainname: internal
  #   # http://localhost:9090
  #   ports:
  #     - 9090:9090
  #   expose:
  #     - 9090
  #   restart: unless-stopped
  #   volumes:
  #     - ./config/prometheus/:/etc/prometheus/
  #     - prometheus_data:/prometheus
  #   command:
  #     - '--config.file=/etc/prometheus/prometheus.yml'
  #     - '--storage.tsdb.path=/prometheus'
  #     - '--web.console.libraries=/etc/prometheus/console_libraries'
  #     - '--web.console.templates=/etc/prometheus/consoles'
  #     - '--storage.tsdb.retention=200h'
  #     - '--web.enable-lifecycle'
  #   # networks:
  #   #   - prometheus-monitor-net
  #   labels:
  #     org.label-schema.group: "prometheus-monitoring"
  # node-exporter:
  #   image: prom/node-exporter:latest
  #   container_name: node-exporter
  #   # http://localhost:9100/metrics
  #   ports:
  #     - "9100:9100"
  #   expose:
  #     - 9100
  #   restart: unless-stopped
  #   volumes:
  #     - /proc:/host/proc:ro
  #     - /sys:/host/sys:ro
  #     - /:/rootfs:ro
  #   command:
  #     - '--path.procfs=/host/proc'
  #     - '--path.rootfs=/rootfs'
  #     - '--path.sysfs=/host/sys'
  #     - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
  #   # networks:
  #   #   - prometheus-monitor-net
  #   labels:
  #     org.label-schema.group: "prometheus-monitoring"
  # pushgateway:
  #   image: prom/pushgateway:latest
  #   container_name: pushgateway
  #   ports:
  #     - "9091:9091"
  #   expose:
  #     - 9091
  #   restart: unless-stopped
  #   networks:
  #     - prometheus-monitor-net
  #   labels:
  #     org.label-schema.group: "prometheus-monitoring"
  # alertmanager:
  #   image: prom/alertmanager:latest
  #   container_name: alertmanager
  #   ports:
  #     - "9093:9093"
  #   expose:
  #     - 9093
  #   restart: unless-stopped
  #   volumes:
  #     - ./config/prometheus/:/etc/alertmanager/
  #   command:
  #     - '--config.file=/etc/alertmanager/alertmanager.yml'
  #     - '--storage.path=/alertmanager'
  #   networks:
  #     - prometheus-monitor-net
  #   labels:
  #     org.label-schema.group: "prometheus-monitoring"
  # grafana:
  #   image: grafana/grafana:latest
  #   hostname: grafana
  #   domainname: internal
  #   environment:
  #     - GF_SECURITY_ADMIN_PASSWORD=admin
  #     - GF_SERVER_DOMAIN=localhost
  #   # http://localhost:3000
  #   ports:
  #     - 3000:3000
  #   expose:
  #     - 3000
  #   restart: unless-stopped
  #   volumes:
  #     - grafana_data:/var/lib/grafana
  #   # networks:
  #   #   - prometheus-monitor-net
  #   labels:
  #     org.label-schema.group: "prometheus-monitoring"
###############################################################################
# MessageQueue
  # rabbitmq:
    # image: rabbitmq:3-management
    # hostname: rabbitmq-server
    # domainname: internal
    # environment:
      # - ENV=DEV
      # - RABBITMQ_DEFAULT_USER=admin
      # - RABBITMQ_DEFAULT_PASS=admin
    # ports:
      # - 5672:5672
      # - 15672:15672
    # restart: unless-stopped
    # healthcheck:
      # test: ["CMD", "curl", "-f", "http://localhost:5672"]
      # interval: 30s
      # timeout: 10s
      # retries: 5
  # kafka-1:
    # image: wurstmeister/kafka:latest
    # hostname: kafka-1
    # domainname: internal
    # depends_on:
      # - zookeeper-1
    # environment:
      # KAFKA_ADVERTISED_HOST_NAME: localhost
      # KAFKA_BROKER_ID: 1
      # KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181
      # KAFKA_CREATE_TOPICS: "mykafka:1:1"
      # KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    # ports:
      # - 9092:9092
    # restart: unless-stopped
###############################################################################
# Storage
  redis-db:
    image: redis:latest
    hostname: redis-db
    domainname: internal
    environment:
      - ENV=DEV
    ports:
      - 6379:6379
    restart: unless-stopped
    # healthcheck:
    #   test: redis-cli -h localhost ping
    #   interval: 30s
    #   timeout: 10s
    #   retries: 5
    volumes:
      - redis_data:/data
  mysql-db:
    image: mysql:latest
    hostname: mysql-db
    domainname: internal
    environment:
      - ENV=DEV
      - MYSQL_ROOT_PASSWORD=123456
      - MYSQL_USER=test
      - MYSQL_PASSWORD=test
    ports:
      - 3306:3306
    restart: unless-stopped
    volumes:
      - mysql_data:/var/lib/mysql
    # healthcheck:
    #   test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "--user=test", "--password=test"]
    #   interval: 5s
    #   timeout: 2s
    #   retries: 3
  #   volumes:
  #     - "D:/workspace/projects/java_leetcode/docker/config/mysql:/etc/mysql"
  #     - "D:/workspace/projects/java_leetcode/docker/data/mysql/data:/var/lib/mysql"
  #     - "D:/workspace/projects/java_leetcode/docker/data/mysql/logs:/var/log/mysql"
  # postgres-db:
  #   image: postgres:latest
  #   hostname: postgres-db
  #   domainname: internal
  #   environment:
  #     POSTGRES_PASSWORD: 123456
  #   ports:
  #     - 5432:5432
  #   restart: unless-stopped
  #   volumes:
  #     - postgres_data:/var/lib/postgresql
  # clickhouse-db:
  #   image: yandex/clickhouse-server:latest
  #   hostname: clickhouse-db
  #   domainname: internal
  #   environment:
  #     - ENV=DEV
  #   ports:
  #     - 8123:8123
  #     - 9009:9009
  #     - 9090:9090
  #   restart: unless-stopped
  #   ulimits:
  #     nofile:
  #       soft: 262144
  #       hard: 262144
    # volumes:
    #     - /Users/liuzhao/Downloads
    #   - $HOME/some_clickhouse_database:/var/lib/clickhouse
  mongo-db:
    image: mongo:latest
    hostname: mongo-db
    domainname: internal
    environment:
      - AUTH=yes
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=admin
    ports:
      - 27017:27017
    restart: unless-stopped
    volumes:
      - mongo_data:/data/db
      - mongo_data:/var/log/mongo_datadb
  # gremlin-console:
  #   image: tinkerpop/gremlin-console:latest
  #   hostname: gremlin-console
  #   domainname: internal
  #   ports:
  #     - 8182:8182
  #   restart: unless-stopped
###############################################################################
# Search
# https://hub.docker.com/_/elasticsearch?tab=tags&page=1&ordering=last_updated
# https://hub.docker.com/_/kibana?tab=tags&page=1&ordering=last_updated
# http://localhost:9200/_cat/health?v
# http://localhost:5601
  # elk-elasticsearch-1:
  #   image: docker.elastic.co/elasticsearch/elasticsearch:7.14.1
  #   hostname: elk-elasticsearch-1
  #   domainname: internal
  #   environment:
  #     - ENV=DEV
  #     - ES_JAVA_OPTS=-Xms256m -Xmx256m
  #     - discovery.type=single-node
  #   ulimits:
  #     memlock:
  #       soft: -1
  #       hard: -1
  #   ports:
  #     - 9200:9200
  #     - 9300:9300
  #   restart: unless-stopped
  #   healthcheck:
  #     test: curl -s http://localhost:9200 >/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
  # elk-kibana-1:
  #   image: docker.elastic.co/kibana/kibana:7.14.1
  #   hostname: elk-kibana-1
  #   domainname: internal
  #   environment:
  #     - ENV=DEV
  #     - SERVER_NAME=elk-kibana-1
  #     - ELASTICSEARCH_HOSTS=http://elk-elasticsearch-1:9200
  #     - ELASTICSEARCH_URL=http://elk-elasticsearch-1:9200
  #   ports:
  #     - 5601:5601
  #   depends_on:
  #     - elk-elasticsearch-1
  #   healthcheck:
  #     test: curl -s http://localhost:5601 >/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5
volumes:
  redis_data: {}
  mysql_data: {}
  postgres_data: {}
  mongo_data: {}
  prometheus_data: {}
  grafana_data: {}

# networks:
  # prometheus-monitor-net:
  #   driver: bridge